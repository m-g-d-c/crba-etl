{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_dictionary import query_dataDict\n",
    "from transformation.destination import destination\n",
    "from transformation.dataflow import dataflow\n",
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read from data_dictionary all API sources (so far only two among all indicators populated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to excel data dictionary in repo\n",
    "data_dict_file = './data_dictionary/indicator_dictionary_TM_v1.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get indicators that are extracted by API (code and address in dataframe)\n",
    "api_code_addr_df = query_dataDict.get_API_code_address_etc(data_dict_file)\n",
    "len(api_code_addr_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform transformations on raw data extracted from API sources\n",
    "I could do the transformations in the same loop from extraction. For the sake of this notebook clarity I will repeat the loop below assuming data has already been extracted.\n",
    "\n",
    "*Output:* One big csv with all the input to warehouse AND its equivalent pieces splitted for indicators in different csv's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data destination path\n",
    "raw_path = './data_raw/'\n",
    "# name of transmonee dataflow in UNICEF warehouse\n",
    "dataflow_out = \"ECARO:TRANSMONEE(1.0)\"\n",
    "# transformed data destination path\n",
    "trans_path = './data_transformed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform indicator: DM_BRTS, from dataflow: DM\n",
      "Transform indicator: DM_POP_URBN, from dataflow: DM\n",
      "Transform indicator: DM_FRATE_TOT, from dataflow: DM\n",
      "Transform indicator: NT_BW_LBW, from dataflow: NUTRITION\n",
      "Transform indicator: CME_MRY0, from dataflow: CME\n",
      "Transform indicator: CME_MRY0T4, from dataflow: CME\n",
      "Transform indicator: CME_MRM0, from dataflow: CME\n",
      "Transform indicator: MNCH_MMR, from dataflow: MNCH\n",
      "Transform indicator: HVA_PMTCT_ARV_CVG, from dataflow: HIV_AIDS\n",
      "Transform indicator: MNCH_PNCMOM, from dataflow: MNCH\n",
      "Transform indicator: MNCH_PNEUCARE, from dataflow: MNCH\n",
      "Transform indicator: IM_DTP3, from dataflow: IMMUNISATION\n",
      "Transform indicator: IM_MCV2, from dataflow: IMMUNISATION\n",
      "Transform indicator: NT_BF_EIBF, from dataflow: NUTRITION\n",
      "Transform indicator: NT_BF_EXBF, from dataflow: NUTRITION\n",
      "Transform indicator: NT_CF_MAD, from dataflow: NUTRITION\n",
      "Transform indicator: NT_ANT_WHZ_PO2, from dataflow: NUTRITION\n",
      "Transform indicator: NT_ANT_HAZ_NE2, from dataflow: NUTRITION\n",
      "Transform indicator: ECD_CHLD_36-59M_ADLT_SRC, from dataflow: ECD\n",
      "Transform indicator: PT_CHLD_Y0T4_REG, from dataflow: PT\n",
      "Transform indicator: PT_CHLD_1-14_PS-PSY-V_CGVR, from dataflow: PT\n",
      "Transform indicator: ECD_CHLD_U5_LFT-ALN, from dataflow: ECD\n",
      "Transform indicator: GN_MTNTY_LV_BNFTS, from dataflow: GENDER\n",
      "Transform indicator: GN_PTNTY_LV_BNFTS, from dataflow: GENDER\n",
      "Transform indicator: ECD_CHLD_36-59M_LMPSL, from dataflow: ECD\n"
     ]
    }
   ],
   "source": [
    "# destination dataframe from TMEE DSD (data structure definition)\n",
    "dest_dsd = destination('TMEE')\n",
    "dest_dsd_df = pd.DataFrame(columns=dest_dsd.get_csv_columns(), dtype=str)\n",
    "\n",
    "# Re write the loop along `api_code_addr_df` dataframe\n",
    "for index, row in api_code_addr_df.iterrows():\n",
    "\n",
    "    indicator_code = row['Code']\n",
    "    indicator_source = row['Data_Source']\n",
    "    indicator_notes = row['Obs_Footnote']\n",
    "    \n",
    "    # \"metadata\" from data dictionary retained for dataflow constants\n",
    "    # if any of these below are dataflow columns, then they won't be used\n",
    "    # Development NOTE: redefine this logic if we want data dictionary predominance\n",
    "    constants = {\n",
    "        'UNICEF_INDICATOR': indicator_code,\n",
    "        'DATA_SOURCE': indicator_source,\n",
    "        'OBS_FOOTNOTE': indicator_notes\n",
    "    }\n",
    "    \n",
    "    # Just for prototype --> skip indicators not downloaded\n",
    "    if os.path.exists(f\"{raw_path}{indicator_code}.csv\"):\n",
    "        # build dataframe with indicator raw data\n",
    "        data_raw = pd.read_csv(f\"{raw_path}{indicator_code}.csv\", dtype=str)\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    # retain only codes form csv headers (recall HTTP header: application/vnd.sdmx.data+csv;version=1.0.0)\n",
    "    raw_columns = data_raw.columns.values\n",
    "    rename_dict = {k:v.split(':')[0] for k,v in zip(raw_columns,raw_columns)}\n",
    "    data_raw.rename(columns=rename_dict,inplace=True)\n",
    "    \n",
    "    # get dataflow from data raw anchor [0,0]\n",
    "    text = data_raw.iloc[0,0]\n",
    "    pattern = ':(.+?)\\('\n",
    "    dataflow_key = re.findall(pattern, text)[0]\n",
    "    \n",
    "    print(f\"Transform indicator: {indicator_code}, from dataflow: {dataflow_key}\")\n",
    "    \n",
    "    # instantiate dataflow class with the actual one\n",
    "    dflow_actual = dataflow(dataflow_key)\n",
    "    if dflow_actual.cod_map:\n",
    "        # map the codes - normalization - works 'inplace'\n",
    "        dflow_actual.map_codes(data_raw)\n",
    "    # map the columns\n",
    "    data_map = dflow_actual.map_dataframe(data_raw, constants)\n",
    "    # append to destination dataframe\n",
    "    dest_dsd_df = dest_dsd_df.append(data_map)\n",
    "    \n",
    "    # save transformed indicator info independently (through pandas)\n",
    "    data_trans = pd.DataFrame(columns=dest_dsd.get_csv_columns(), dtype=str)\n",
    "    data_trans = data_trans.append(data_map)\n",
    "    # destination Dataflow: corresponding UNICEF Warehouse DSD name\n",
    "    data_trans['Dataflow'] = dataflow_out\n",
    "    # save file\n",
    "    data_trans.to_csv(f\"{trans_path}{indicator_code}.csv\",index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All transform done? Add destination DSD name to destination dataframe\n",
    "dest_dsd_df['Dataflow'] = dataflow_out\n",
    "# save file\n",
    "load_path = './data_2_load/'\n",
    "load_file = 'TMEE_2_load'\n",
    "dest_dsd_df.to_csv(f\"{load_path}{load_file}.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
