
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook contains code used to populate data dictionary\n",
    "It is in development state and not cleaned at all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beto\\anaconda3\\lib\\site-packages\\pandas_datareader\\compat\\__init__.py:7: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  from pandas.util.testing import assert_frame_equal\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas_datareader import wb\n",
    "from data_dictionary.append_df_to_excel import append_df_to_excel\n",
    "# from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the excel tmee database\n",
    "path_file = './populate_data_dictionary/TM Indicators Flow Revised Database - 2020306 SP ED ECD -working file v-6 Aug 2020_beto.xlsx'\n",
    "indicators = pd.read_excel(path_file, sheet_name='TM Revised database', header = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter indicators that are new or retained from excel tmee data base\n",
    "logic_not_removed = indicators['Status in the new `db'].str.lower().str.contains('new|retained')\n",
    "# filter logic_not_removed that are not boolean\n",
    "logic_not_null = logic_not_removed.notnull()\n",
    "# and operator from logic above\n",
    "logic_not_removed_null = logic_not_removed & logic_not_null\n",
    "not_removed_indicators = indicators[logic_not_removed_null]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# point to indicators with helix: or helix code: in excel tmee data base\n",
    "logic_helix = not_removed_indicators['Data Source'].str.lower().str.contains(\"helix:|helix code:|helix \")\n",
    "# filter logic_helix that are not boolean\n",
    "logic_not_null = logic_helix.notnull()\n",
    "# and operator from logic above\n",
    "logic_helix_not_null = logic_helix & logic_not_null\n",
    "not_removed_indicators['Code'] = not_removed_indicators[logic_helix_not_null]['Data Source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_removed_indicators[logic_helix_not_null]['Data Source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the code for API requests\n",
    "not_removed_indicators['Code'] = not_removed_indicators['Code'].str.replace('Helix: ','')\\\n",
    ".str.replace('Helix code: ','').str.replace('/', '').str.replace('\\\\', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a function from stackoverflow to append data dictionary\n",
    "path_file = './populate_data_dictionary/indicator_dictionary_TM_v1.xlsx'\n",
    "append_df_to_excel(path_file, not_removed_indicators.iloc[21:,[2,105]], sheet_name='Indicator', startrow=22,\n",
    "                   startcol = 4, header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize helix Api names as Helix for source names\n",
    "not_removed_indicators['Source Name'] = 'Helix: ' + not_removed_indicators[logic_helix_not_null]['Code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place list of helix api's in source\n",
    "path_file = './populate_data_dictionary/indicator_dictionary_TM_v1.xlsx'\n",
    "append_df_to_excel(path_file, not_removed_indicators.loc[logic_helix_not_null,'Source Name'].iloc[2:],\n",
    "                   sheet_name='Source', startrow=6,\n",
    "                   startcol = 2, header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_removed_indicators.loc[logic_helix_not_null,'Source Name'].iloc[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_removed_indicators.loc[logic_helix_not_null,'Code'].iloc[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_removed_indicators.iloc[21:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the code for API requests\n",
    "not_removed_indicators['Code'].str.replace('Helix: ','').str.replace('Helix code: ','').str.replace('/', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a function from stackoverflow\n",
    "path_file = './populate_data_dictionary/indicator_dictionary_TM_v1.xlsx'\n",
    "append_df_to_excel(path_file, not_removed_indicators.iloc[21:,-1], sheet_name='Indicator', startrow=22,\n",
    "                   startcol = 5, header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(helix_source_indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now I want to plug correctly the codes in the populated Excel data dictionary\n",
    "# should I join these two tables on name?\n",
    "not_removed_indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the indicator names of these into Excel (ideally to populate our dictionary)\n",
    "# this solution does not properly work (creates a new spreadsheet)\n",
    "\n",
    "# path to existing excel file\n",
    "# I know before hand which indicators I want to add and the startrow and starcol parameters\n",
    "path_file = './populate_data_dictionary/indicator_dictionary_TM_v1.xlsx'\n",
    "with pd.ExcelWriter(path_file, mode='a', engine=\"openpyxl\") as writer:\n",
    "    indicators[logic_not_removed_null].iloc[21:,2].to_excel(writer, sheet_name='Indicator',\n",
    "                                                                       header = False, index = False,\n",
    "                                                                       startrow = 22, startcol = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the codes from helix API based indicators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get info from new or retained indicators\n",
    "indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function from stackoverflow by MaxU\n",
    "def append_df_to_excel(filename, df, sheet_name='Sheet1', startrow=None,\n",
    "                       truncate_sheet=False, \n",
    "                       **to_excel_kwargs):\n",
    "    \"\"\"\n",
    "    Append a DataFrame [df] to existing Excel file [filename]\n",
    "    into [sheet_name] Sheet.\n",
    "    If [filename] doesn't exist, then this function will create it.\n",
    "\n",
    "    Parameters:\n",
    "      filename : File path or existing ExcelWriter\n",
    "                 (Example: '/path/to/file.xlsx')\n",
    "      df : dataframe to save to workbook\n",
    "      sheet_name : Name of sheet which will contain DataFrame.\n",
    "                   (default: 'Sheet1')\n",
    "      startrow : upper left cell row to dump data frame.\n",
    "                 Per default (startrow=None) calculate the last row\n",
    "                 in the existing DF and write to the next row...\n",
    "      truncate_sheet : truncate (remove and recreate) [sheet_name]\n",
    "                       before writing DataFrame to Excel file\n",
    "      to_excel_kwargs : arguments which will be passed to `DataFrame.to_excel()`\n",
    "                        [can be dictionary]\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    from openpyxl import load_workbook\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    # ignore [engine] parameter if it was passed\n",
    "    if 'engine' in to_excel_kwargs:\n",
    "        to_excel_kwargs.pop('engine')\n",
    "\n",
    "    writer = pd.ExcelWriter(filename, engine='openpyxl')\n",
    "\n",
    "    # Python 2.x: define [FileNotFoundError] exception if it doesn't exist \n",
    "    try:\n",
    "        FileNotFoundError\n",
    "    except NameError:\n",
    "        FileNotFoundError = IOError\n",
    "\n",
    "\n",
    "    try:\n",
    "        # try to open an existing workbook\n",
    "        writer.book = load_workbook(filename)\n",
    "\n",
    "        # get the last row in the existing Excel sheet\n",
    "        # if it was not specified explicitly\n",
    "        if startrow is None and sheet_name in writer.book.sheetnames:\n",
    "            startrow = writer.book[sheet_name].max_row\n",
    "\n",
    "        # truncate sheet\n",
    "        if truncate_sheet and sheet_name in writer.book.sheetnames:\n",
    "            # index of [sheet_name] sheet\n",
    "            idx = writer.book.sheetnames.index(sheet_name)\n",
    "            # remove [sheet_name]\n",
    "            writer.book.remove(writer.book.worksheets[idx])\n",
    "            # create an empty sheet [sheet_name] using old index\n",
    "            writer.book.create_sheet(sheet_name, idx)\n",
    "\n",
    "        # copy existing sheets\n",
    "        writer.sheets = {ws.title:ws for ws in writer.book.worksheets}\n",
    "    except FileNotFoundError:\n",
    "        # file does not exist yet, we will create it\n",
    "        pass\n",
    "\n",
    "    if startrow is None:\n",
    "        startrow = 0\n",
    "\n",
    "    # write out the new sheet\n",
    "    df.to_excel(writer, sheet_name, startrow=startrow, **to_excel_kwargs)\n",
    "\n",
    "    # save the workbook\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dev section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test append df to excel function\n",
    "path_file = './populate_data_dictionary/test.xlsx'\n",
    "append_df_to_excel(path_file, not_removed_indicators.iloc[21:,[2,105]], sheet_name='Indicator', startrow=22,\n",
    "                   startcol = 4, header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking forward to get more sources that could be extracted as API\n",
    "not_removed_indicators['Data Source'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.search('timss').tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './tests/'\n",
    "file_name = 'LO.PISA.MAT'\n",
    "wb.download(indicator=file_name, country=['AL', 'AM', 'TR', 'TM', 'BA'], start=1960, end=2020).to_csv(f\"{path}{file_name}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if TIMSS exam from pandas datareader retrieves same info provided by source in TMEE database Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'https://api.worldbank.org/v2/en/country/AM/indicator/LO.TIMSS.MAT4.FE?format=json&per_page=20000&source=12'\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"country\": {\n",
      "        \"id\": \"AM\",\n",
      "        \"value\": \"Armenia\"\n",
      "    },\n",
      "    \"countryiso3code\": \"ARM\",\n",
      "    \"date\": \"1970\",\n",
      "    \"decimal\": 0,\n",
      "    \"indicator\": {\n",
      "        \"id\": \"LO.TIMSS.MAT4.FE\",\n",
      "        \"value\": \"TIMSS: Mean performance on the mathematics scale for fourth grade students, female\"\n",
      "    },\n",
      "    \"obs_status\": \"\",\n",
      "    \"unit\": \"\",\n",
      "    \"value\": null\n",
      "}\n",
      "[('2100', None), ('2095', None), ('2090', None), ('2085', None), ('2080', None), ('2075', None), ('2070', None), ('2065', None), ('2060', None), ('2055', None), ('2050', None), ('2045', None), ('2040', None), ('2035', None), ('2030', None), ('2025', None), ('2020', None), ('2019', None), ('2018', None), ('2017', None), ('2016', None), ('2015', None), ('2014', None), ('2013', None), ('2012', None), ('2011', 454.183991529079), ('2010', None), ('2009', None), ('2008', None), ('2007', 504.024671259021), ('2006', None), ('2005', None), ('2004', None), ('2003', 462.281133790492), ('2002', None), ('2001', None), ('2000', None), ('1999', None), ('1998', None), ('1997', None), ('1996', None), ('1995', None), ('1994', None), ('1993', None), ('1992', None), ('1991', None), ('1990', None), ('1989', None), ('1988', None), ('1987', None), ('1986', None), ('1985', None), ('1984', None), ('1983', None), ('1982', None), ('1981', None), ('1980', None), ('1979', None), ('1978', None), ('1977', None), ('1976', None), ('1975', None), ('1974', None), ('1973', None), ('1972', None), ('1971', None), ('1970', None)]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def pprint(json_var):\n",
    "    print(json.dumps(json_var, indent=4, sort_keys=True))\n",
    "\n",
    "resp_json = response.json()\n",
    "pprint(resp_json[1][66])\n",
    "print([(r['date'],r['value']) for r in resp_json[1]])\n",
    "# pd.read_json(resp_json[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if there's dissagregation in Sex for UIS indicator `EDUNF_STU_PER_L02_PUB`\n",
    "It does work also the same for `EDUNF_STU_PER_L02_PRV`, `EDUNF_STU_PER_L01_PUB`, etc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STAT_UNIT</th>\n",
       "      <th>UNIT_MEASURE</th>\n",
       "      <th>EDU_LEVEL</th>\n",
       "      <th>EDU_CAT</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>GRADE</th>\n",
       "      <th>SECTOR_EDU</th>\n",
       "      <th>EDU_ATTAIN</th>\n",
       "      <th>WEALTH_QUINTILE</th>\n",
       "      <th>...</th>\n",
       "      <th>COUNTRY_ORIGIN</th>\n",
       "      <th>REGION_DEST</th>\n",
       "      <th>IMM_STATUS</th>\n",
       "      <th>REF_AREA</th>\n",
       "      <th>TIME_PERIOD</th>\n",
       "      <th>OBS_VALUE</th>\n",
       "      <th>UNIT_MULT</th>\n",
       "      <th>OBS_STATUS</th>\n",
       "      <th>FREQ</th>\n",
       "      <th>DECIMALS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STU</td>\n",
       "      <td>PER</td>\n",
       "      <td>L01</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>INST_PRIV</td>\n",
       "      <td>_Z</td>\n",
       "      <td>_Z</td>\n",
       "      <td>...</td>\n",
       "      <td>W00</td>\n",
       "      <td>W00</td>\n",
       "      <td>_Z</td>\n",
       "      <td>AL</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Z</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STU</td>\n",
       "      <td>PER</td>\n",
       "      <td>L01</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>INST_PRIV</td>\n",
       "      <td>_Z</td>\n",
       "      <td>_Z</td>\n",
       "      <td>...</td>\n",
       "      <td>W00</td>\n",
       "      <td>W00</td>\n",
       "      <td>_Z</td>\n",
       "      <td>AL</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Z</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STU</td>\n",
       "      <td>PER</td>\n",
       "      <td>L01</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>INST_PRIV</td>\n",
       "      <td>_Z</td>\n",
       "      <td>_Z</td>\n",
       "      <td>...</td>\n",
       "      <td>W00</td>\n",
       "      <td>W00</td>\n",
       "      <td>_Z</td>\n",
       "      <td>AL</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Z</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STU</td>\n",
       "      <td>PER</td>\n",
       "      <td>L01</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>INST_PRIV</td>\n",
       "      <td>_Z</td>\n",
       "      <td>_Z</td>\n",
       "      <td>...</td>\n",
       "      <td>W00</td>\n",
       "      <td>W00</td>\n",
       "      <td>_Z</td>\n",
       "      <td>AL</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Z</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STU</td>\n",
       "      <td>PER</td>\n",
       "      <td>L01</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>INST_PRIV</td>\n",
       "      <td>_Z</td>\n",
       "      <td>_Z</td>\n",
       "      <td>...</td>\n",
       "      <td>W00</td>\n",
       "      <td>W00</td>\n",
       "      <td>_Z</td>\n",
       "      <td>AL</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Z</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>STU</td>\n",
       "      <td>PER</td>\n",
       "      <td>L01</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>INST_PRIV</td>\n",
       "      <td>_Z</td>\n",
       "      <td>_Z</td>\n",
       "      <td>...</td>\n",
       "      <td>W00</td>\n",
       "      <td>W00</td>\n",
       "      <td>_Z</td>\n",
       "      <td>AL</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Z</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>STU</td>\n",
       "      <td>PER</td>\n",
       "      <td>L01</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>INST_PRIV</td>\n",
       "      <td>_Z</td>\n",
       "      <td>_Z</td>\n",
       "      <td>...</td>\n",
       "      <td>W00</td>\n",
       "      <td>W00</td>\n",
       "      <td>_Z</td>\n",
       "      <td>AL</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Z</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>STU</td>\n",
       "      <td>PER</td>\n",
       "      <td>L01</td>\n",
       "      <td>_T</td>\n",
       "      <td>F</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>INST_PRIV</td>\n",
       "      <td>_Z</td>\n",
       "      <td>_Z</td>\n",
       "      <td>...</td>\n",
       "      <td>W00</td>\n",
       "      <td>W00</td>\n",
       "      <td>_Z</td>\n",
       "      <td>AL</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Z</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>STU</td>\n",
       "      <td>PER</td>\n",
       "      <td>L01</td>\n",
       "      <td>_T</td>\n",
       "      <td>F</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>INST_PRIV</td>\n",
       "      <td>_Z</td>\n",
       "      <td>_Z</td>\n",
       "      <td>...</td>\n",
       "      <td>W00</td>\n",
       "      <td>W00</td>\n",
       "      <td>_Z</td>\n",
       "      <td>AL</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Z</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>STU</td>\n",
       "      <td>PER</td>\n",
       "      <td>L01</td>\n",
       "      <td>_T</td>\n",
       "      <td>F</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>INST_PRIV</td>\n",
       "      <td>_Z</td>\n",
       "      <td>_Z</td>\n",
       "      <td>...</td>\n",
       "      <td>W00</td>\n",
       "      <td>W00</td>\n",
       "      <td>_Z</td>\n",
       "      <td>AL</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Z</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>STU</td>\n",
       "      <td>PER</td>\n",
       "      <td>L01</td>\n",
       "      <td>_T</td>\n",
       "      <td>F</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>INST_PRIV</td>\n",
       "      <td>_Z</td>\n",
       "      <td>_Z</td>\n",
       "      <td>...</td>\n",
       "      <td>W00</td>\n",
       "      <td>W00</td>\n",
       "      <td>_Z</td>\n",
       "      <td>AL</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Z</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>STU</td>\n",
       "      <td>PER</td>\n",
       "      <td>L01</td>\n",
       "      <td>_T</td>\n",
       "      <td>F</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>INST_PRIV</td>\n",
       "      <td>_Z</td>\n",
       "      <td>_Z</td>\n",
       "      <td>...</td>\n",
       "      <td>W00</td>\n",
       "      <td>W00</td>\n",
       "      <td>_Z</td>\n",
       "      <td>AL</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Z</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>STU</td>\n",
       "      <td>PER</td>\n",
       "      <td>L01</td>\n",
       "      <td>_T</td>\n",
       "      <td>F</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>INST_PRIV</td>\n",
       "      <td>_Z</td>\n",
       "      <td>_Z</td>\n",
       "      <td>...</td>\n",
       "      <td>W00</td>\n",
       "      <td>W00</td>\n",
       "      <td>_Z</td>\n",
       "      <td>AL</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Z</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>STU</td>\n",
       "      <td>PER</td>\n",
       "      <td>L01</td>\n",
       "      <td>_T</td>\n",
       "      <td>M</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>INST_PRIV</td>\n",
       "      <td>_Z</td>\n",
       "      <td>_Z</td>\n",
       "      <td>...</td>\n",
       "      <td>W00</td>\n",
       "      <td>W00</td>\n",
       "      <td>_Z</td>\n",
       "      <td>AL</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Z</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>STU</td>\n",
       "      <td>PER</td>\n",
       "      <td>L01</td>\n",
       "      <td>_T</td>\n",
       "      <td>M</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>INST_PRIV</td>\n",
       "      <td>_Z</td>\n",
       "      <td>_Z</td>\n",
       "      <td>...</td>\n",
       "      <td>W00</td>\n",
       "      <td>W00</td>\n",
       "      <td>_Z</td>\n",
       "      <td>AL</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Z</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>STU</td>\n",
       "      <td>PER</td>\n",
       "      <td>L01</td>\n",
       "      <td>_T</td>\n",
       "      <td>M</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>INST_PRIV</td>\n",
       "      <td>_Z</td>\n",
       "      <td>_Z</td>\n",
       "      <td>...</td>\n",
       "      <td>W00</td>\n",
       "      <td>W00</td>\n",
       "      <td>_Z</td>\n",
       "      <td>AL</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Z</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>STU</td>\n",
       "      <td>PER</td>\n",
       "      <td>L01</td>\n",
       "      <td>_T</td>\n",
       "      <td>M</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>INST_PRIV</td>\n",
       "      <td>_Z</td>\n",
       "      <td>_Z</td>\n",
       "      <td>...</td>\n",
       "      <td>W00</td>\n",
       "      <td>W00</td>\n",
       "      <td>_Z</td>\n",
       "      <td>AL</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Z</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>STU</td>\n",
       "      <td>PER</td>\n",
       "      <td>L01</td>\n",
       "      <td>_T</td>\n",
       "      <td>M</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>INST_PRIV</td>\n",
       "      <td>_Z</td>\n",
       "      <td>_Z</td>\n",
       "      <td>...</td>\n",
       "      <td>W00</td>\n",
       "      <td>W00</td>\n",
       "      <td>_Z</td>\n",
       "      <td>AL</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Z</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>STU</td>\n",
       "      <td>PER</td>\n",
       "      <td>L01</td>\n",
       "      <td>_T</td>\n",
       "      <td>M</td>\n",
       "      <td>_T</td>\n",
       "      <td>_T</td>\n",
       "      <td>INST_PRIV</td>\n",
       "      <td>_Z</td>\n",
       "      <td>_Z</td>\n",
       "      <td>...</td>\n",
       "      <td>W00</td>\n",
       "      <td>W00</td>\n",
       "      <td>_Z</td>\n",
       "      <td>AL</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Z</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STAT_UNIT UNIT_MEASURE EDU_LEVEL EDU_CAT SEX AGE GRADE SECTOR_EDU  \\\n",
       "0        STU          PER       L01      _T  _T  _T    _T  INST_PRIV   \n",
       "1        STU          PER       L01      _T  _T  _T    _T  INST_PRIV   \n",
       "2        STU          PER       L01      _T  _T  _T    _T  INST_PRIV   \n",
       "3        STU          PER       L01      _T  _T  _T    _T  INST_PRIV   \n",
       "4        STU          PER       L01      _T  _T  _T    _T  INST_PRIV   \n",
       "5        STU          PER       L01      _T  _T  _T    _T  INST_PRIV   \n",
       "6        STU          PER       L01      _T  _T  _T    _T  INST_PRIV   \n",
       "7        STU          PER       L01      _T   F  _T    _T  INST_PRIV   \n",
       "8        STU          PER       L01      _T   F  _T    _T  INST_PRIV   \n",
       "9        STU          PER       L01      _T   F  _T    _T  INST_PRIV   \n",
       "10       STU          PER       L01      _T   F  _T    _T  INST_PRIV   \n",
       "11       STU          PER       L01      _T   F  _T    _T  INST_PRIV   \n",
       "12       STU          PER       L01      _T   F  _T    _T  INST_PRIV   \n",
       "13       STU          PER       L01      _T   M  _T    _T  INST_PRIV   \n",
       "14       STU          PER       L01      _T   M  _T    _T  INST_PRIV   \n",
       "15       STU          PER       L01      _T   M  _T    _T  INST_PRIV   \n",
       "16       STU          PER       L01      _T   M  _T    _T  INST_PRIV   \n",
       "17       STU          PER       L01      _T   M  _T    _T  INST_PRIV   \n",
       "18       STU          PER       L01      _T   M  _T    _T  INST_PRIV   \n",
       "\n",
       "   EDU_ATTAIN WEALTH_QUINTILE  ... COUNTRY_ORIGIN REGION_DEST IMM_STATUS  \\\n",
       "0          _Z              _Z  ...            W00         W00         _Z   \n",
       "1          _Z              _Z  ...            W00         W00         _Z   \n",
       "2          _Z              _Z  ...            W00         W00         _Z   \n",
       "3          _Z              _Z  ...            W00         W00         _Z   \n",
       "4          _Z              _Z  ...            W00         W00         _Z   \n",
       "5          _Z              _Z  ...            W00         W00         _Z   \n",
       "6          _Z              _Z  ...            W00         W00         _Z   \n",
       "7          _Z              _Z  ...            W00         W00         _Z   \n",
       "8          _Z              _Z  ...            W00         W00         _Z   \n",
       "9          _Z              _Z  ...            W00         W00         _Z   \n",
       "10         _Z              _Z  ...            W00         W00         _Z   \n",
       "11         _Z              _Z  ...            W00         W00         _Z   \n",
       "12         _Z              _Z  ...            W00         W00         _Z   \n",
       "13         _Z              _Z  ...            W00         W00         _Z   \n",
       "14         _Z              _Z  ...            W00         W00         _Z   \n",
       "15         _Z              _Z  ...            W00         W00         _Z   \n",
       "16         _Z              _Z  ...            W00         W00         _Z   \n",
       "17         _Z              _Z  ...            W00         W00         _Z   \n",
       "18         _Z              _Z  ...            W00         W00         _Z   \n",
       "\n",
       "   REF_AREA TIME_PERIOD OBS_VALUE UNIT_MULT OBS_STATUS FREQ DECIMALS  \n",
       "0        AL        2000         0         0          Z    A        5  \n",
       "1        AL        2004         0         0          Z    A        5  \n",
       "2        AL        2008         0         0          Z    A        5  \n",
       "3        AL        2009         0         0          Z    A        5  \n",
       "4        AL        2010         0         0          Z    A        5  \n",
       "5        AL        2011         0         0          Z    A        5  \n",
       "6        AL        2012         0         0          Z    A        5  \n",
       "7        AL        2000         0         0          Z    A        5  \n",
       "8        AL        2008         0         0          Z    A        5  \n",
       "9        AL        2009         0         0          Z    A        5  \n",
       "10       AL        2010         0         0          Z    A        5  \n",
       "11       AL        2011         0         0          Z    A        5  \n",
       "12       AL        2012         0         0          Z    A        5  \n",
       "13       AL        2000         0         0          Z    A        5  \n",
       "14       AL        2008         0         0          Z    A        5  \n",
       "15       AL        2009         0         0          Z    A        5  \n",
       "16       AL        2010         0         0          Z    A        5  \n",
       "17       AL        2011         0         0          Z    A        5  \n",
       "18       AL        2012         0         0          Z    A        5  \n",
       "\n",
       "[19 rows x 28 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('https://api.uis.unesco.org/sdmx/data/UNESCO,EDU_NON_FINANCE,3.0/STU.PER.L01.....INST_PRIV..............AL?startPeriod=1950&endPeriod=2050&format=csv&locale=en&subscription-key=9d48382df9ad408ca538352a4186791b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter indicators that are new or retained from excel tmee data base\n",
    "logic_not_removed = indicators['Status in the new `db'].str.lower().str.contains('new|retained')\n",
    "# filter logic_not_removed that are not boolean\n",
    "logic_not_null = logic_not_removed.notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(indicators[logic_not_removed & logic_not_null])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open existing excel file\n",
    "path_file = './populate_data_dictionary/indicator_dictionary_TM_v1.xlsx'\n",
    "# book = load_workbook(path_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open excel writer\n",
    "writer = pd.ExcelWriter(path_file, engine='openpyxl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open existing excel file\n",
    "path_file = './populate_data_dictionary/indicator_dictionary_TM_v1.xlsx'\n",
    "with pd.ExcelWriter(path_file, mode='a', engine=\"openpyxl\") as writer:\n",
    "    indicators[logic_not_removed & logic_not_null].iloc[21:,2].to_excel(writer, sheet_name='Indicator',\n",
    "                                                                       header = False, index = False,\n",
    "                                                                       startrow = 22, startcol = 4)\n",
    "# df.to_excel(writer, sheet_name='Sheet3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# point to indicators with data source not null\n",
    "logic_not_null = indicators.iloc[:,5].notnull()\n",
    "# get those that contains 'helix' in data source\n",
    "logic_helix = indicators[logic_not_null]['Data Source'].str.lower().str.contains('helix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# point to indicators with helix: or helix code: in excel tmee data base\n",
    "logic_helix = indicators['Data Source'].str.lower().str.contains('helix:|helix code:')\n",
    "# filter logic_helix that are not boolean\n",
    "logic_not_null = logic_helix.notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators[logic_helix & logic_not_null]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators[logic_not_removed_null].iloc[21:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators['Data Source'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators['Status in the new `db'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logic_not_removed = indicators['Status in the new `db'].str.lower().str.contains('new|retained')\n",
    "indicators[logic_not_removed.isnull()].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(indicators['Status in the new `db'].unique()).str.lower().str.contains('new|retained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
